{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "# user input parameters\n",
    "filename = '7_10_swash_tv_07_07_2023_2_11940.0_slomo_1p9'\n",
    "beach_slope = 1.9\n",
    "\n",
    "# setup\n",
    "tf.keras.backend.clear_session()\n",
    "tf_model_version = \"swash_tv_v14\"\n",
    "model = tf.keras.models.load_model(tf_model_version + \"_model\")\n",
    "cap = cv2.VideoCapture(filename + \".mp4\") # \n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS) #fps\n",
    "slomo_rate = 6\n",
    "flip_image_lr = True\n",
    "m_per_pixel = 1/1000\n",
    "img_padding = 25\n",
    "frame_start = 0\n",
    "frame_end = 1000000000000 # just a really big number so the whole video is processed\n",
    "cap.set(1, frame_start)\n",
    "IMG_SIZE_pre = 1520 # 760 original image size is 1520x358\n",
    "IMG_SIZE_WID_PRE_CROP = 358\n",
    "IMG_SIZE_WID_pre = 160\n",
    "crop_flag = True\n",
    "downsample_ratio = 0.5\n",
    "if crop_flag == True:\n",
    "    IMG_SIZE = int(IMG_SIZE_pre*downsample_ratio)\n",
    "    IMG_SIZE_WID = int(IMG_SIZE_WID_pre*downsample_ratio)\n",
    "else:\n",
    "    IMG_SIZE = IMG_SIZE_pre\n",
    "    IMG_SIZE_WID = IMG_SIZE_WID_pre\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%% MAIN WHILE LOOP %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "\n",
    "frame_end_count = 0\n",
    "cap.set(1, frame_start)\n",
    "frame_reduced_list = []\n",
    "print(\"Extracting frames...\")\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    ret, frame = cap.read()    \n",
    "    if frame_end_count > frame_end:\n",
    "        break\n",
    "    \n",
    "    if ret == True:\n",
    "        \n",
    "        if flip_image_lr == True:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        if crop_flag == True:\n",
    "            # crop top section of image away\n",
    "            frame = frame[IMG_SIZE_WID_PRE_CROP - IMG_SIZE_WID_pre:,:]\n",
    "            wid = int(frame.shape[1] * downsample_ratio)\n",
    "            hig = int(frame.shape[0] * downsample_ratio)\n",
    "            dim = (wid, hig)\n",
    "            frame_reduced = cv2.resize(frame, dim, interpolation=cv2.INTER_NEAREST_EXACT)\n",
    "        else:\n",
    "            frame_reduced = cv2.resize(frame, (IMG_SIZE_WID, IMG_SIZE))\n",
    "        \n",
    "        frame_reduced_list.append(frame_reduced)\n",
    "        frame_end_count = frame_end_count + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"Processing frames through Unet model...\")\n",
    "\n",
    "predictions = []\n",
    "frames_proc = 100\n",
    "# do N frames at a time\n",
    "for i in range(0, len(frame_reduced_list), frames_proc):\n",
    "    if len(frame_reduced_list) - i < frames_proc:\n",
    "        residual = len(frame_reduced_list) - i\n",
    "        frame_red_list_tf = np.array(frame_reduced_list[i:i + residual])\n",
    "        frame_red_list_tf = frame_red_list_tf / 255\n",
    "        frame_red_list_tf = frame_red_list_tf.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "        predict_mtx = model.predict([frame_red_list_tf])\n",
    "        # pad past the angle brackets\n",
    "        predict_mtx[:,:,0:img_padding,:] = [0,1]\n",
    "        predict_mtx[:,:,-img_padding:,:] = [0,1]\n",
    "        predictions.extend(predict_mtx)\n",
    "        \n",
    "    else:\n",
    "        frame_red_list_tf = np.array(frame_reduced_list[i:i + frames_proc])\n",
    "        frame_red_list_tf = frame_red_list_tf / 255\n",
    "        frame_red_list_tf = frame_red_list_tf.reshape(-1, IMG_SIZE_WID, IMG_SIZE, 3)\n",
    "        predict_mtx = model.predict([frame_red_list_tf])\n",
    "        # pad past the angle brackets\n",
    "        predict_mtx[:,:,0:img_padding,:] = [0,1]\n",
    "        predict_mtx[:,:,-img_padding:,:] = [0,1]\n",
    "        predictions.extend(predict_mtx)\n",
    "\n",
    "print(\"Unet processing finished, now post processing data...\")\n",
    "\n",
    "# https://stackoverflow.com/questions/43892506/opencv-python-rotate-image-without-cropping-sides\n",
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2] # image shape has 3 dimensions\n",
    "    # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "    image_center = (width/2, height/2) \n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
    "    \n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0,0])\n",
    "    abs_sin = abs(rotation_mat[0,1])\n",
    "    \n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w/2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h/2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h), flags=cv2.INTER_NEAREST)\n",
    "    return rotated_mat\n",
    "\n",
    "# create a graph of the water surface depth at all times measured up from the bottom of the image.\n",
    "x_vals_all = []\n",
    "z_vals_all = []\n",
    "t_vals_all = []\n",
    "h_vals_all = []\n",
    "mov_img_list = []\n",
    "j = 0\n",
    "for prediction in predictions:\n",
    "    test_image = frame_reduced_list[j]\n",
    "    \n",
    "    # process the prediction into a colour map\n",
    "    test_model_guess = np.array(np.argmax(prediction, axis=-1), dtype=np.uint8)\n",
    "    test_model_guess = np.where(test_model_guess == 1, 255, test_model_guess)\n",
    "    test_model_guess = np.where(test_model_guess == 0, 10, test_model_guess)\n",
    "    test_model_guess = np.array(test_model_guess, dtype=np.uint8)\n",
    "    \n",
    "    # colour the mask image\n",
    "    r_channel = np.array(test_model_guess)\n",
    "    b_channel = np.array(test_model_guess)\n",
    "    g_channel = np.array(test_model_guess)\n",
    "    \n",
    "    # foamWake\n",
    "    r_channel[r_channel == 10] = 155\n",
    "    b_channel[b_channel == 10] = 150\n",
    "    g_channel[g_channel == 10] = 80\n",
    "    \n",
    "    colour_img = cv2.merge((b_channel,g_channel,r_channel))\n",
    "    \n",
    "    # produce a transparent overaly image of the mask on the original image for visualization purposes.\n",
    "    colour_img = cv2.addWeighted(test_image, 0.9, colour_img, 0.2, 0)\n",
    "    \n",
    "    # rotate image\n",
    "    colour_img = rotate_image(colour_img, beach_slope)\n",
    "    \n",
    "    mov_img_list.append(colour_img)\n",
    "    \n",
    "    test_model_guess = test_model_guess[:,img_padding:-img_padding]\n",
    "    test_model_guess = rotate_image(test_model_guess, beach_slope)\n",
    "    test_model_guess = np.where(test_model_guess == 0, 255, test_model_guess)\n",
    "    test_model_guess_cols = test_model_guess.T\n",
    "    \n",
    "    x_list = []\n",
    "    t_list = []\n",
    "    z_list = []\n",
    "    h_list = []\n",
    "    # extract top pixel from every column of the mask\n",
    "    # take x_rot_offset away if rotated by Beta\n",
    "    x_rot_offset = int(test_image.shape[0]*np.sin(np.deg2rad(beach_slope)))\n",
    "    x_pad_offset = int(img_padding*np.cos(np.deg2rad(beach_slope)))\n",
    "    for col in range(x_rot_offset, len(test_model_guess_cols), 1):\n",
    "        # get indexes of all 210 values\n",
    "        water_surf = np.where(test_model_guess_cols[col] == 10)\n",
    "        if len(water_surf[0]) > 0:\n",
    "            # z values need to be from bottom of image up\n",
    "            z_val = (test_model_guess.shape[0] - min(water_surf[0]))*m_per_pixel/downsample_ratio\n",
    "            z_list.append(z_val)\n",
    "            cv2.circle(colour_img, (col + x_pad_offset, min(water_surf[0])), radius=1, color=[0, 0, 255])\n",
    "            h_list.append(z_val - (col - x_rot_offset)*np.tan(np.deg2rad(beach_slope))*m_per_pixel/downsample_ratio)\n",
    "            \n",
    "        else:\n",
    "            z_list.append(0)\n",
    "            h_list.append(0)\n",
    "        \n",
    "        x_list.append((col - x_rot_offset)*m_per_pixel/downsample_ratio)\n",
    "        t_list.append(j*(1/frame_rate)/slomo_rate)\n",
    "        \n",
    "    x_vals_all.append(x_list)\n",
    "    z_vals_all.append(z_list)\n",
    "    t_vals_all.append(t_list)\n",
    "    h_vals_all.append(h_list)\n",
    "    j = j + 1\n",
    "\n",
    "x_vals_all_flat = np.concatenate(x_vals_all).ravel()\n",
    "t_vals_all_flat = np.concatenate(t_vals_all).ravel()\n",
    "z_vals_all_flat = np.concatenate(z_vals_all).ravel()\n",
    "h_vals_all_flat = np.concatenate(h_vals_all).ravel()\n",
    "\n",
    "# save values in csv file\n",
    "rows = zip(x_vals_all_flat, t_vals_all_flat, z_vals_all_flat, h_vals_all_flat)\n",
    "with open(filename + \"_data.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['x (m)', 't (s)', 'z (m)', 'h (m)'])\n",
    "    for row in rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "ax.set_ylabel('t (s)')\n",
    "ax.set_xlabel('x (m)')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "sc = plt.scatter(x_vals_all_flat, t_vals_all_flat, c=h_vals_all_flat, vmin=0, vmax=0.15, cmap='nipy_spectral', s=0.05, marker='.')\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('depth (m)')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(filename + \"_graph.png\", bbox_inches='tight', dpi=300)\n",
    "\n",
    "# create video\n",
    "video_recorded = cv2.VideoWriter(filename + \"_annotated.mp4\",\n",
    "                                 cv2.VideoWriter_fourcc(*'DIVX'), frame_rate,\n",
    "                                 (mov_img_list[0].shape[1], mov_img_list[0].shape[0]))\n",
    "\n",
    "print(\"Writing a video...\")\n",
    "for i in range(0, len(mov_img_list), 1):\n",
    "    video_recorded.write(mov_img_list[i])\n",
    "video_recorded.release()\n",
    "\n",
    "print(\"Swash TV analysis finished, data has been saved as a depth coloured timestack.\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
